---
title: 操作系统
date: 2023-01-08 16:51:33
tags: 
- 操作系统
categories:
- 计算机基础
---

## 基础

### 什么是操作系统

- **操作系统（Operating System，简称 OS）是管理计算机硬件与软件资源的程序，是计算机的基石。**
- **操作系统本质上是一个运行在计算机上的软件程序 ，用于管理计算机硬件和软件资源。** 举例：运行在你电脑上的所有应用程序都通过操作系统来调用系统内存以及磁盘等等硬件。
- **操作系统存在屏蔽了硬件层的复杂性。** 操作系统就像是硬件使用的负责人，统筹着各种相关事项。
- **操作系统的内核（Kernel）是操作系统的核心部分，它负责系统的内存管理，硬件设备的管理，文件系统的管理以及应用程序的管理**。 内核是连接应用程序和硬件的桥梁，决定着系统的性能和稳定性。

![Kernel_Layout](https://yumoimgbed.oss-cn-shenzhen.aliyuncs.com/img/202212221335185.png)

------

### 系统调用

为了避免操作系统和关键数据被用户程序破坏，将处理器的执行状态分为内核态和用户态。

根据进程访问资源的特点，可以把进程在系统上的运行分为两个级别：

- **用户态（user mode）**：用户态运行的进程可以直接读取用户程序的数据；
- **内核态（kernel mode）**：可以简单的理解内核态运行的进程或程序几乎可以访问计算机的任何资源，不受限制。

内核态是**操作系统管理程序执行时**所处的状态，能够执行包含特权指令在内的一切指令，能够访问系统内所有的存储空间。用户态是**用户程序执行时**处理器所处的状态，不能执行特权指令，只能访问用户地址空间。

运行的用户程序中，凡是与内核态级别的资源有关的操作（如文件管理、进程控制、内存管理等)，都必须通过**系统调用**方式（在用户态中需要调用内核态级别子功能）向操作系统提出服务请求，并由操作系统代为完成。

这些系统调用按功能大致可分为如下几类：

- **设备管理**：完成设备的请求或释放，以及设备启动等功能
- **文件管理**：完成文件的读、写、创建及删除等功能
- **进程控制**：完成进程的创建、撤销、阻塞及唤醒等功能
- **进程通信**：完成进程之间的消息传递或信号传递等功能
- **内存管理**：完成内存的分配、回收以及获取作业占用内存区大小及地址等功能

------

## 进程&线程

**进程是资源分配的最小单位，线程是CPU调度的最小单位。**

一个进程有一个JVM实例，一个进程中可以有多个线程，多个线程共享同一个进程的**堆**和**方法区 (JDK1.8 之后的元空间)**资源，但是每个线程有自己的**程序计数器**、**虚拟机栈** 和 **本地方法栈**。

![](https://yumoimgbed.oss-cn-shenzhen.aliyuncs.com/img/java-runtime-data-areas-jdk1.8.png)

线程是进程划分成的更小的运行单位，一个进程在其执行的过程中可以产生多个线程。线程和进程最大的不同在于基本上各进程是独立的，而各线程则不一定，因为同一进程中的线程极有可能会相互影响。线程执行开销小，但不利于资源的管理和保护；而进程正相反。

------

### 进程状态

- **创建状态(new)** ：进程正在被创建，尚未到就绪状态；
- **就绪状态(ready)** ：进程已处于准备运行状态，即进程获得了除了处理器之外的一切所需资源，一旦得到处理器资源（处理器分配的时间片）即可运行；
- **运行状态(running)** ：进程正在处理器上上运行（单核 CPU 下任意时刻只有一个进程处于运行状态）；
- **阻塞状态(waiting)** ：又称为等待状态，进程正在等待某一事件而暂停运行如等待某资源为可用或等待 IO 操作完成。即使处理器空闲，该进程也不能运行；
- **结束状态(terminated)** ：进程正在从系统中消失。可能是进程正常结束或其他原因中断退出运行。

![进程状态切换](https://yumoimgbed.oss-cn-shenzhen.aliyuncs.com/img/202212221427855.png)

------

### 进程间通信方式

每个进程各自有不同的用户地址空间，任何一个进程的全局变量在另一个进程中都看不到，所以进程之间要交换数据必须通过内核，在内核中开辟一块缓冲区，进程1把数据从用户空间拷到内核缓冲区，进程2再从内核缓冲区把数据读走，内核提供的这种机制称为**进程间通信（IPC，InterProcess Communication）**



![进程间通信模型](https://yumoimgbed.oss-cn-shenzhen.aliyuncs.com/img/202212221431743.webp)

**进程间通信模型**

- **管道/匿名管道(Pipes)** 

  - **所谓的管道，就是内核里面的一串缓存**。**对于匿名管道，它的通信范围是存在父子关系的进程**。
  - 因为管道没有实体，也就是没有管道文件，只能通过 fork 来复制父进程 fd 文件描述符，来达到通信的目的。
  - 匿名管道的生命周期，是随进程的创建而建立，随进程的结束而销毁

- **有名管道(Named Pipes)** : 

  - 匿名管道由于没有名字，只能用于亲缘关系的进程间通信。为了克服这个缺点，提出了有名管道。
  - 有名管道严格遵循**先进先出(first in first out)**。有名管道以**磁盘文件**的方式存在，**它可以在不相关的进程间也能相互通信**；

- **信号(Signal)** ：信号是进程间通信机制中**唯一的异步通信机制**，用于通知接收进程某个事件已经发生；

  ![img](https://yumoimgbed.oss-cn-shenzhen.aliyuncs.com/img/1281379-3eed8cca67aa9f55.png)

- **消息队列(Message Queuing)** 

  - **消息队列是保存在内核中的消息链表**，具有特定的格式，存放在内存中并由消息队列标识符标识。管道和消息队列的通信数据都是**先进先出**的原则。
  - 消息队列存放在**内核**中，只有在内核重启（即，操作系统重启）或者显式地删除一个消息队列时，该消息队列才会被真正的删除。
  - 消息队列生命周期随内核，如果没有释放消息队列或者没有关闭操作系统，消息队列会一直存在

  消息队列可以实现消息的随机查询，消息不一定要以先进先出的次序读取，也可以按消息的类型读取。比 FIFO 更有优势。**消息队列克服了信号承载信息量少，管道只能承载无格式字节流以及缓冲区大小受限等缺点**；

- **信号量(Semaphores)**

  - **信号量其实是一个整型的计数器，主要用于实现进程间的互斥与同步，而不是用于缓存进程间通信的数据**。

    信号量表示资源的数量，控制信号量的方式有两种原子操作：

    - 一个是 **P 操作**，这个操作会把信号量减去 1，相减后如果信号量 < 0，则表明资源已被占用，进程需阻塞等待；相减后如果信号量 >= 0，则表明还有资源可使用，进程可正常继续执行。
    - 另一个是 **V 操作**，这个操作会把信号量加上 1，相加后如果信号量 <= 0，则表明当前有阻塞中的进程，于是会将该进程唤醒运行；相加后如果信号量 > 0，则表明当前没有阻塞中的进程；

    P 操作是用在进入共享资源之前，V 操作是用在离开共享资源之后，这两个操作是必须成对出现的。

- **共享内存(Shared memory)** 

  - **共享内存的机制，就是拿出一块虚拟地址空间来，映射到相同的物理内存中**。
  - 使得多个进程可以访问同一块内存空间，不同进程可以及时看到对方进程中对共享内存中数据的更新。这种方式需要依靠某种同步操作，如互斥锁和信号量等。可以说这是最有用的进程间通信方式；

  ![img](https://yumoimgbed.oss-cn-shenzhen.aliyuncs.com/img/20210317231249749.png)

- **套接字(Sockets)** : 此方法主要用于在客户端和服务器之间通过网络进行通信。套接字是支持 TCP/IP 的网络通信的基本操作单元，可以看做是不同主机之间的进程进行双向通信的端点，简单的说就是通信的两方的一种约定，用套接字中的相关函数来完成通信过程。

------

### 线程同步方式

线程同步是两个或多个共享关键资源的线程的并发执行。应该同步线程以避免关键的资源使用冲突。操作系统一般有下面三种线程同步的方式：

- **互斥量(Mutex)**：采用互斥对象机制，只有拥有互斥对象的线程才有访问公共资源的权限。因为互斥对象只有一个，所以可以保证公共资源不会被多个线程同时访问。比如 Java 中的 synchronized 关键词和各种 Lock 都是这种机制；

- **信号量(Semaphore)**：它允许同一时刻多个线程访问同一资源，但是需要控制同一时刻访问此资源的最大线程数量；

  > **信号量与互斥量之间的区别：**
  >
  > - 互斥量用于线程的互斥，信号量用于线程的同步。这是互斥量和信号量的根本区别，也就是互斥和同步之间的区别。
  >
  >   - **互斥：**是指某一资源同时只允许一个访问者对其进行访问，具有唯一性和排它性。但互斥无法限制访问者对资源的访问顺序，即访问是**无序**的。
  >
  >   - **同步：**是指在互斥的基础上（大多数情况），通过其它机制实现访问者对资源的**有序**访问。
  >
  >     在大多数情况下，同步已经实现了互斥，特别是所有写入资源的情况必定是互斥的。少数情况是指可以允许多个访问者同时访问资源
  >
  > - 互斥量值只能为0/1，信号量值可以为非负整数。
  >
  >   也就是说，一个互斥量只能用于一个资源的互斥访问，它不能实现多个资源的多线程互斥问题。信号量可以实现多个同类资源的多线程互斥和同步。当信号量为单值信号量是，也可以完成一个资源的互斥访问。
  >
  > - 互斥量的加锁和解锁必须由**同一线程**分别对应使用，信号量可以由一个线程释放，另一个线程得到。

- **事件(Event)** ：Wait/Notify，通过通知操作的方式来保持多线程同步，还可以方便的实现多线程优先级的比较操作。

------

### 进程调度算法

为了确定首先执行哪个进程以及最后执行哪个进程以实现最大 CPU 利用率，计算机科学家已经定义了一些算法，它们是：

- **先到先服务(FCFS)调度算法** : 从就绪队列中选择一个**最先进入该队列的进程**为之分配资源，使它立即执行并一直执行到完成或发生某事件而被阻塞放弃占用 CPU 时再重新调度；

- **短作业优先(SJF)的调度算法** : 从就绪队列中选出一个**估计运行时间最短的进程**为之分配资源，使它立即执行并一直执行到完成或发生某事件而被阻塞放弃占用 CPU 时再重新调度；

- **时间片轮转调度算法** : 时间片轮转调度是一种最古老，最简单，最公平且使用最广的算法，又称 RR(Round robin)调度。每个进程被分配一个时间段，称作它的时间片，即该进程允许运行的时间；

  <img src="https://yumoimgbed.oss-cn-shenzhen.aliyuncs.com/img/20210317231806318.png" alt="线程切换" style="zoom:50%;" />

- **多级反馈队列调度算法** ：前面介绍的几种进程调度的算法都有一定的局限性。如**短进程优先的调度算法，仅照顾了短进程而忽略了长进程** 。多级反馈队列调度算法既能使高优先级的作业得到响应又能使短作业（进程）迅速完成。，因而它是目前**被公认的一种较好的进程调度算法**，UNIX 操作系统采取的便是这种调度算法；

- **优先级调度** ： 为每个流程分配优先级，首先执行具有最高优先级的进程，依此类推。具有相同优先级的进程以 FCFS 方式执行。可以根据内存要求，时间要求或任何其他资源要求来确定优先级。

------

### 死锁

死锁描述的是这样一种情况：多个进程/线程同时被阻塞，它们中的一个或者全部都在等待某个资源被释放。由于进程/线程被无限期地阻塞，因此程序不可能正常终止。

#### 产生死锁条件

- **互斥**：资源必须处于非共享模式，即一次只有一个进程可以使用。如果另一进程申请该资源，那么必须等待直到该资源被释放为止；
- **占有并等待**：一个进程至少应该占有一个资源，并等待另一资源，而该资源被其他进程所占有；
- **非抢占**：资源不能被抢占。只能在持有资源的进程完成任务后，该资源才会被释放；
- **循环等待**：有一组等待进程 `{P0, P1,..., Pn}`， `P0` 等待的资源被 `P1` 占有，`P1` 等待的资源被 `P2` 占有，……，`Pn-1` 等待的资源被 `Pn` 占有，`Pn` 等待的资源被 `P0` 占有。

这四个条件是产生死锁的**必要条件**，也就是说只要系统发生死锁，这些条件必然成立，而只要上述条件之一不满足，就不会发生产生死锁。

#### 解决死锁

解决死锁的方法可以从多个角度去分析，一般的情况下，有**预防，避免，检测和解除四种**。

- **预防** 是采用某种策略，**限制并发进程对资源的请求**，从而使得死锁的必要条件在系统执行的任何时间上都不满足。
- **避免**则是系统在分配资源时，根据资源的使用情况**提前做出预测**，从而**避免死锁的发生**
- **检测**是指系统设有**专门的机构**，当死锁发生时，该机构能够检测死锁的发生，并精确地确定与死锁有关的进程和资源。
- **解除** 是与检测相配套的一种措施，用于**将进程从死锁状态下解脱出来**。

##### 预防

只要破坏四个必要条件中的任何一个就能够预防死锁的发生。

- 破坏第一个条件**互斥条件**：使得资源是可以同时访问的，这是种简单的方法，磁盘就可以用这种方法管理，但是我们要知道，有很多资源**往往是不能同时访问的** ，所以这种做法在大多数的场合是行不通的；
- 破坏第三个条件**非抢占** ：也就是说可以采用 **剥夺式调度算法**，但剥夺式调度方法目前一般仅适用于**主存资源**和**处理器资源**的分配，并不适用于所有的资源，会导致**资源利用率下降**。

所以一般比较实用的**预防死锁的方法**，是通过考虑破坏第二个条件和第四个条件。

###### 静态分配策略

静态分配策略可以破坏死锁产生的第二个条件（占有并等待）。所谓**静态分配策略**，就是指**一个进程必须在执行前就申请到它所需要的全部资源，并且知道它所要的资源都得到满足之后才开始执行**。进程要么占有所有的资源然后开始执行，要么不占有资源，不会出现占有一些资源等待一些资源的情况。

静态分配策略逻辑简单，实现也很容易，但这种策略**严重地降低了资源利用率**，因为在每个进程所占有的资源中，有些资源是在比较靠后的执行时间里采用的，甚至有些资源是在额外的情况下才是用的，这样就可能造成了一个进程占有了一些**几乎不用的资源而使其他需要该资源的进程产生等待**的情况。

###### 层次分配策略

层次分配策略破坏了产生死锁的第四个条件（循环等待）。在**层次分配策略**下，所有的资源被分成了多个层次，**一个进程得到某一层的一个资源后，它只能再申请较高一层的资源；当一个进程要释放某层的一个资源时，必须先释放所占用的较高层的资源**，按这种策略，是不可能出现循环等待链的，因为那样的话，就出现了已经申请了较高层的资源，反而去申请了较低层的资源，不符合层次分配策略。

##### 避免

将系统的状态分为 **安全状态** 和 **不安全状态** ，每当在未申请者分配资源前先测试系统状态，若把系统资源分配给申请者会产生死锁，则拒绝分配，否则接受申请，并为它分配资源。

> 如果操作系统能够保证所有的进程在有限的时间内得到需要的全部资源，则称系统处于安全状态，否则说系统是不安全的。很显然，系统处于安全状态则不会发生死锁，系统若处于不安全状态则可能发生死锁。

通过**银行家算法**改善解决了**资源使用率低的问题**，但是它要不断地检测每个进程对各类资源的占用和申请情况，以及做 **安全性检查** ，需要花费较多的时间。

当一个进程申请使用资源的时候，银行家算法通过先 **试探** 分配给该进程资源，然后通过安全性算法判断分配后的系统是否处于安全状态，若不安全则试探分配作废，让该进程继续等待。

![银行家算法图示](https://yumoimgbed.oss-cn-shenzhen.aliyuncs.com/img/202212221540094.png)

****



##### 检测

对资源的分配加以限制可以**预防和避免**死锁的发生，但是都不利于各进程对系统资源的**充分共享**。解决死锁问题的另一条途径是**死锁检测和解除**。这种方法对资源的分配不加以任何限制，也不采取死锁避免措施，但系统**定时地运行一个“死锁检测”**的程序，判断系统内是否出现死锁，如果检测到系统发生了死锁，再采取措施去解除它。

操作系统中的每一刻时刻的**系统状态**都可以用**进程-资源分配图**来表示，进程-资源分配图是描述进程和资源申请及分配关系的一种有向图，可用于**检测系统是否处于死锁状态**。

用一个方框表示每一个资源类，方框中的黑点表示该资源类中的各个资源，每个进程用一个圆圈表示，用 **有向边** 来表示**进程申请资源和资源被分配的情况**。

图中 2-21 是**进程-资源分配图**的一个例子，其中共有三个资源类，每个进程的资源占有和申请情况已清楚地表示在图中。在这个例子中，由于存在 **占有和等待资源的环路** ，导致一组进程永远处于等待资源的状态，发生了 **死锁**。

![进程-资源分配图](https://yumoimgbed.oss-cn-shenzhen.aliyuncs.com/img/202212221545116.jpeg)

进程-资源分配图中存在环路并不一定是发生了死锁。因为循环等待资源仅仅是死锁发生的必要条件，而不是充分条件。图 2-22 便是一个有环路而无死锁的例子。虽然进程 P1 和进程 P3 分别占用了一个资源 R1 和一个资源 R2，并且因为等待另一个资源 R2 和另一个资源 R1 形成了环路，但进程 P2 和进程 P4 分别占有了一个资源 R1 和一个资源 R2，它们申请的资源得到了满足，在有限的时间里会归还资源，于是进程 P1 或 P3 都能获得另一个所需的资源，环路自动解除，系统也就不存在死锁状态了。

- 如果进程-资源分配图中无环路，则此时系统没有发生死锁；
- 如果进程-资源分配图中有环路，且每个资源类仅有一个资源，则系统中已经发生了死锁；
- 如果进程-资源分配图中有环路，且涉及到的资源类有多个资源，此时系统未必会发生死锁。如果能在进程-资源分配图中找出一个**既不阻塞又非独立的进程**，该进程能够在有限的时间内归还占有的资源，也就是把边给消除掉了，重复此过程，直到能在有限的时间内**消除所有的边** ，则不会发生死锁，否则会发生死锁。

当死锁检测程序检测到存在死锁发生时，应设法让其解除，让系统从死锁状态中恢复过来，常用的解除死锁的方法有以下四种：

- **立即结束所有进程的执行，重新启动操作系统**：这种方法简单，但以前所在的工作全部作废，损失很大；
- **撤销涉及死锁的所有进程，解除死锁后继续运行**：这种方法能彻底打破**死锁的循环等待**条件，但将付出很大代价，例如有些进程可能已经计算了很长时间，由于被撤销而使产生的部分结果也被消除了，再重新执行时还要再次进行计算；
- **逐个撤销涉及死锁的进程，回收其资源直至死锁解除**；
- **抢占资源**：从涉及死锁的一个或几个进程中抢占资源，把夺得的资源再分配给涉及死锁的进程直至死锁解除。

------

## 内存管理

操作系统的内存管理主要负责内存的分配与回收（malloc 函数：申请内存，free 函数：释放内存），另外地址转换也就是将逻辑地址转换成相应的物理地址等功能也是操作系统内存管理做的事情。

### 内存管理机制

**连续分配管理方式**和**非连续分配管理方式**这两种。连续分配管理方式是指为一个用户程序分配一个连续的内存空间，常见的如 **块式管理** 。同样地，非连续分配管理方式允许一个程序使用的内存分布在离散或者说不相邻的内存中，常见的如**页式管理** 和 **段式管理**。

- **块式管理** ： 远古时代的计算机操作系统的内存管理方式。将内存分为几个固定大小的块，每个块中只包含一个进程。如果程序运行需要内存的话，操作系统就分配给它一块，如果程序运行只需要很小的空间的话，分配的这块内存很大一部分几乎被浪费了。这些在每个块中未被利用的空间，我们称之为**碎片**；
- **页式管理** ：把主存分为大小相等且固定的一页一页的形式，页较小，相比于块式管理的划分粒度更小，提高了内存利用率，减少了碎片。页式管理通过**页表**对应逻辑地址和物理地址；
- **段式管理** ： 页式管理虽然提高了内存利用率，但是页式管理其中的页并无任何实际意义。 段式管理把主存分为一段段的，段是有实际意义的，每个段定义了一组逻辑信息，例如,有主程序段 MAIN、子程序段 X、数据段 D 及栈段 S 等。 段式管理通过**段表**对应逻辑地址和物理地址。

简单来说：页是物理单位，段是逻辑单位。分页可以有效提高内存利用率，分段可以更好满足用户需求。

**段页式管理机制**结合了段式管理和页式管理的优点。简单来说段页式管理机制就是把主存先分成若干段，每个段又分成若干页，也就是说 **段页式管理机制** 中段与段之间以及段的内部的都是离散的。

------

### 快表&多级页表

编程一般只有可能和逻辑地址打交道，比如在 C 语言中，指针里面存储的数值就可以理解成为内存里的一个地址，这个地址也就是我们说的逻辑地址，**逻辑地址由操作系统决定**。**物理地址指的是真实物理内存中地址**，更具体一点来说就是内存地址寄存器中的地址。物理地址是内存单元真正的地址。

在分页内存管理中，很重要的两点：

- 虚拟地址到物理地址的转换要快；
- 解决虚拟地址空间大，页表也会很大的问题。

#### 快表

为了提高虚拟地址到物理地址的转换速度，操作系统在 **页表方案** 基础之上引入了 **快表** 来加速虚拟地址到物理地址的转换。我们可以把快表理解为一种特殊的高速缓冲存储器（Cache），其中的内容是页表的一部分或者全部内容。作为页表的 Cache，它的作用与页表相似，但是提高了访问速率。由于采用页表做地址转换，读写内存数据时 CPU 要访问两次主存。有了快表，有时只要访问一次高速缓冲存储器，一次主存，这样可加速查找并提高指令执行速度。

使用快表之后的地址转换流程是这样的：

1. 根据虚拟地址中的页号查快表；
2. 如果该页在快表中，直接从快表中读取相应的物理地址；
3. 如果该页不在快表中，就访问内存中的页表，再从页表中得到物理地址，同时将页表中的该映射表项添加到快表中；
4. 当快表填满后，又要登记新页时，就按照一定的淘汰策略淘汰掉快表中的一个页。

#### 多级页表

引入多级页表的主要目的是为了避免把全部页表一直放在内存中占用过多空间，特别是那些根本就不需要的页表就不需要保留在内存中。多级页表属于时间换空间的典型场景。

------

### 分页机制&分段机制

**共同点**：

- 分页机制和分段机制都是为了提高内存利用率，减少内存碎片；
- 页和段都是离散存储的，所以两者都是离散分配内存的方式。但是，每个页和段中的内存是连续的。

**区别**：

- 页的大小是固定的，由操作系统决定；而段的大小不固定，取决于我们当前运行的程序；
- 分页仅仅是为了满足操作系统内存管理的需求，而段是逻辑信息的单位，在程序中可以体现为代码段，数据段，能够更好满足用户的需要。

------

### CPU 寻址

现代处理器使用的是一种称为 **虚拟寻址(Virtual Addressing)** 的寻址方式。**使用虚拟寻址，CPU 需要将虚拟地址翻译成物理地址，这样才能访问到真实的物理内存。** 实际上完成虚拟地址转换为物理地址转换的硬件是 CPU 中含有一个被称为 **内存管理单元（Memory Management Unit, MMU）** 的硬件。

页表是被缓存在内存中的，尽管内存的速度相对于硬盘来说已经非常快了，但与 CPU 还是有所差距。**为了防止每次地址翻译操作都需要去访问内存，CPU 使用了高速缓存与 TLB 来缓存页表条目（Page Table Entry, PTE）。**



![通过 MMU 寻找真实物理地址](https://yumoimgbed.oss-cn-shenzhen.aliyuncs.com/img/202212241439117.png)



#### 页表

MMU需要借助存放在**内存**中的**页表**来动态翻译虚拟地址，该页表由操作系统管理。

操作系统通过将虚拟内存分割为**大小固定的块**来作为硬盘和内存之间的传输单位，这个块被称为**虚拟页（Virtual Page, VP）**，每个虚拟页的大小为`P=2^p`字节。物理内存也会按照这种方法分割为**物理页（Physical Page, PP）**，大小也为`P`字节。

**页表是一个元素为页表条目（Page Table Entry, PTE）的集合**，每个虚拟页在页表中一个固定偏移量的位置上都有一个PTE。下面是 PTE 仅含有一个有效位标记的页表结构，该有效位代表这个虚拟页是否被缓存在物理内存中。



![img](https://yumoimgbed.oss-cn-shenzhen.aliyuncs.com/img/202212241536587.webp)



**由于CPU每次进行地址翻译的时候都需要经过PTE，所以如果想控制内存系统的访问，可以在PTE上添加一些额外的许可位（例如读写权限、内核权限等）**，这样只要有指令违反了这些许可条件，CPU就会触发一个一般保护故障，将控制权传递给内核中的异常处理程序。一般这种异常被称为“段错误”（Segmentation Fault）。

如果虚拟页已经缓存到 PTE 中，就是页命中；反之，就是缺页的情况。

#### 虚拟地址作用

**如果直接把物理地址暴露出来的话会带来严重问题，比如可能对操作系统造成伤害以及给同时运行多个程序造成困难。**

没有虚拟地址空间的时候，**程序直接访问和操作的都是物理内存**。

- 用户程序可以访问任意内存，寻址内存的每个字节，这样就很容易（有意或者无意）破坏操作系统，造成操作系统崩溃；
- 想要同时运行多个程序特别困难，比如你想同时运行一个微信和一个 QQ 音乐都不行。为什么呢？举个简单的例子：微信在运行的时候给内存地址 1xxx 赋值后，QQ 音乐也同样给内存地址 1xxx 赋值，那么 QQ 音乐对内存的赋值就会覆盖微信之前所赋的值，这就造成了微信这个程序就会崩溃。

通过虚拟地址访问内存有以下优势：

- 程序可以使用一系列**相邻的虚拟地址**来访问**物理内存中不相邻的大内存缓冲区**；

- 程序可以使用一系列虚拟地址来访问大于可用物理内存的内存缓冲区（通过虚拟内存可以让程序可以拥有超过系统物理内存大小的可用内存空间）。

  当物理内存的供应量变小时，内存管理器会将物理内存页（通常大小为 4KB）保存到磁盘文件。数据或代码页会根据需要在物理内存与磁盘之间移动；

- **不同进程使用的虚拟地址彼此隔离**。一个进程中的代码无法更改正在由另一进程或操作系统使用的物理内存。

------

## 虚拟内存

**虚拟内存** 使得应用程序认为它拥有连续的可用的内存（一个连续完整的地址空间），而实际上，它通常是被分隔成多个物理内存碎片，还有部分暂时存储在外部磁盘存储器上，在需要时进行数据交换。

与没有使用虚拟内存技术的系统相比，使用这种技术的系统使得大型程序的编写变得更容易，对真正的物理内存（例如 RAM）的使用也更有效率。

- 通过 **虚拟内存** 可以让程序可以拥有**超过系统物理内存大小的可用内存空间**。
- 虚拟内存为每个进程提供了一个一致的、私有的地址空间，它让每个进程产生了一种自己在独享主存的错觉（**每个进程拥有一片连续完整的内存空间**）
- 虚拟内存的重要意义是**它定义了一个连续的虚拟地址空间**，并且 **把内存扩展到硬盘空间**。

### 局部性原理

局部性原理是虚拟内存技术的基础，正是因为程序运行具有局部性原理，才可以只装入部分程序到内存就开始运行。

局部性原理表现在以下两个方面：

- **时间局部性** ：如果程序中的某条指令一旦执行，不久以后该指令可能再次执行；如果某数据被访问过，不久以后该数据可能再次被访问。

  产生时间局部性的典型原因，是由于在程序中存在着大量的循环操作；

- **空间局部性** ：一旦程序访问了某个存储单元，在不久之后，其附近的存储单元也将被访问，即程序在一段时间内所访问的地址，可能集中在一定的范围之内。

  这是因为指令通常是顺序存放、顺序执行的，数据也一般是以向量、数组、表等形式簇聚存储的。

**时间局部性**是通过将**近来使用的指令和数据**保存到**高速缓存存储器**中，并使用高速缓存的层次结构实现。

**空间局部性**通常是使用**较大的高速缓存**，并将**预取机制**集成到**高速缓存控制逻辑**中实现。

虚拟内存技术实际上就是建立了 “内存一外存”的两级存储器的结构，利用局部性原理实现髙速缓存。

------

### 技术实现

虚拟内存的实现有以下三种方式：

- **请求分页存储管理** ：建立在**分页管理**之上，为了支持虚拟存储器功能而增加了**请求调页**功能和**页面置换**功能。请求分页是目前最常用的一种实现虚拟存储器的方法。

  请求分页存储管理系统中，在作业开始运行之前，仅装入当前要执行的部分段即可运行。假如在作业运行的过程中发现要访问的页面不在内存，则由处理器通知操作系统按照对应的**页面置换算法**将相应的页面调入到主存，同时操作系统也可以将暂时不用的页面置换到外存中；

- **请求分段存储管理** ：建立在分段存储管理之上，增加了**请求调段**功能、**分段置换**功能。

  请求分段储存管理方式就如同请求分页储存管理方式一样，在作业开始运行之前，仅装入当前要执行的部分段即可运行；在执行过程中，可使用请求调入中断动态装入要访问但又不在内存的程序段；当内存空间已满，而又需要装入新的段时，根据置换功能适当调出某个段，以便腾出空间而装入新的段；

- **请求段页式存储管理**。

**分页与分页存储管理的不同：**

请求分页存储管理建立在**分页管理**之上。他们的根本区别是**是否将程序全部所需的全部地址空间都装入主存**。请求分页存储管理不要求将作业全部地址空间同时装入主存。基于这一点，请求分页存储管理可以提供虚存，而分页存储管理却不能提供虚存。

上面三种实现方式一般都需要：

- **一定容量的内存和外存**：在载入程序的时候，只需要将程序的一部分装入内存，而将其他部分留在外存；
- **缺页中断**：如果**需执行的指令或访问的数据尚未在内存**（称为缺页或缺段），则由处理器通知操作系统将相应的页面或段**调入到内存**，然后继续执行程序；
- **虚拟地址空间** ：逻辑地址到物理地址的变换。

------

### 页面置换算法

地址映射过程中，若在页面中发现所要访问的页面不在内存中，则发生缺页中断 。

> **缺页中断** 就是要访问的**页**不在主存，需要操作系统将其调入主存后再进行访问。 在这个时候，被内存映射的文件实际上成了一个分页交换文件。

当发生缺页中断时，如果当前内存中并没有空闲的页面，操作系统就必须在内存选择一个页面将其移出内存，以便为即将调入的页面让出空间。

用来选择淘汰哪一页的规则叫做**页面置换算法**，可以把**页面置换算法看成是淘汰页面的规则**。

- **OPT（Optimal） 页面置换算法（最佳页面置换算法）**：最佳置换算法所选择的被淘汰页面将是**以后永不使用的**，或者是**在最长时间内不再被访问的**页面,这样可以保证获得最低的缺页率。但由于人们目前无法预知进程在内存下的若千页面中哪个是未来最长时间内不再被访问的，因而**该算法无法实现**。一般作为衡量其他置换算法的方法；
- **FIFO（First In First Out） 页面置换算法（先进先出页面置换算法）**: 总是淘汰**最先进入内存的**页面，即选择在内存中**驻留时间最久的**页面进行淘汰；
- **LRU （Least Recently Used）页面置换算法（最近最久未使用页面置换算法）**：LRU 算法赋予每个页面一个访问字段，用来记录一个页面自上次被访问以来所经历的时间 T，当须淘汰一个页面时，选择现有页面中其 T 值最大的，即**最近最久未使用的**页面予以淘汰；
- **LFU （Least Frequently Used）页面置换算法（最少使用页面置换算法）**: 该置换算法选择在之前时期**使用最少的**页面作为淘汰页。

------

















操作系统